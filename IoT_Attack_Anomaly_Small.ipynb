{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105389,
     "status": "ok",
     "timestamp": 1718862305775,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "e7T5l90saU1V",
    "outputId": "0167a1a7-513e-4c1f-fa3f-06091d60a707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'faster-kan' already exists and is not an empty directory.\n",
      "Processing /home/jovyan/work/Attack-Detection-on-IoT-Devices-with-KAN/faster-kan\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from efficient-kan==0.1.0) (2.4.1+cu124)\n",
      "Requirement already satisfied: pytest>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from efficient-kan==0.1.0) (8.3.3)\n",
      "Requirement already satisfied: tqdm>=4.66.2 in /opt/conda/lib/python3.10/site-packages (from efficient-kan==0.1.0) (4.66.5)\n",
      "Requirement already satisfied: torchvision>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from efficient-kan==0.1.0) (0.19.1+cu124)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.18.0->efficient-kan==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.18.0->efficient-kan==0.1.0) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.0->efficient-kan==0.1.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.0->efficient-kan==0.1.0) (1.3.0)\n",
      "Building wheels for collected packages: efficient-kan\n",
      "  Building wheel for efficient-kan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficient-kan: filename=efficient_kan-0.1.0-py3-none-any.whl size=31755 sha256=579a4f2df205bc364b12802af6fd168e6688ea7e784fee2211c9151741d7eb24\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b0/ec/51/3e6f456aee4092a7bdd99f6d1bae3aa444216c5068af91f876\n",
      "Successfully built efficient-kan\n",
      "Installing collected packages: efficient-kan\n",
      "  Attempting uninstall: efficient-kan\n",
      "    Found existing installation: efficient-kan 0.1.0\n",
      "    Uninstalling efficient-kan-0.1.0:\n",
      "      Successfully uninstalled efficient-kan-0.1.0\n",
      "Successfully installed efficient-kan-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AthanasiosDelis/faster-kan.git\n",
    "!cd faster-kan && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjh_RdwmD8T2"
   },
   "source": [
    "# ***Libraries :-***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6942,
     "status": "ok",
     "timestamp": 1718862385753,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "Gq806lAMtn7J"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, TargetEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from fasterkan import fasterkan as fkan\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4au4OfxNR1Uh"
   },
   "source": [
    "# ***Preprocessing :-***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 3000,
     "status": "ok",
     "timestamp": 1718862388728,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "uh2h7HbtH7zn",
    "outputId": "5e103c38-2079-46d2-9ae1-0505eec2814e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceID</th>\n",
       "      <th>sourceAddress</th>\n",
       "      <th>sourceType</th>\n",
       "      <th>sourceLocation</th>\n",
       "      <th>destinationServiceAddress</th>\n",
       "      <th>destinationServiceType</th>\n",
       "      <th>destinationLocation</th>\n",
       "      <th>accessedNodeAddress</th>\n",
       "      <th>accessedNodeType</th>\n",
       "      <th>operation</th>\n",
       "      <th>value</th>\n",
       "      <th>normality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightcontrol2</td>\n",
       "      <td>/agent2/lightcontrol2</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>BedroomParents</td>\n",
       "      <td>/agent2/lightcontrol2</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>BedroomParents</td>\n",
       "      <td>/agent2/lightcontrol2</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>registerService</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lightcontrol3</td>\n",
       "      <td>/agent3/lightcontrol3</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>Dinningroom</td>\n",
       "      <td>/agent3/lightcontrol3</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>Dinningroom</td>\n",
       "      <td>/agent3/lightcontrol3</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>registerService</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightcontrol1</td>\n",
       "      <td>/agent1/lightcontrol1</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>BedroomChildren</td>\n",
       "      <td>/agent1/lightcontrol1</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>BedroomChildren</td>\n",
       "      <td>/agent1/lightcontrol1</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>registerService</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lightcontrol4</td>\n",
       "      <td>/agent4/lightcontrol4</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>/agent4/lightcontrol4</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>/agent4/lightcontrol4</td>\n",
       "      <td>/lightControler</td>\n",
       "      <td>registerService</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movement4</td>\n",
       "      <td>/agent4/movement4</td>\n",
       "      <td>/movementSensor</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>/agent4/movement4</td>\n",
       "      <td>/movementSensor</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>/agent4/movement4</td>\n",
       "      <td>/movementSensor</td>\n",
       "      <td>registerService</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sourceID          sourceAddress       sourceType   sourceLocation  \\\n",
       "0  lightcontrol2  /agent2/lightcontrol2  /lightControler   BedroomParents   \n",
       "1  lightcontrol3  /agent3/lightcontrol3  /lightControler      Dinningroom   \n",
       "2  lightcontrol1  /agent1/lightcontrol1  /lightControler  BedroomChildren   \n",
       "3  lightcontrol4  /agent4/lightcontrol4  /lightControler          Kitchen   \n",
       "4      movement4      /agent4/movement4  /movementSensor          Kitchen   \n",
       "\n",
       "  destinationServiceAddress destinationServiceType destinationLocation  \\\n",
       "0     /agent2/lightcontrol2        /lightControler      BedroomParents   \n",
       "1     /agent3/lightcontrol3        /lightControler         Dinningroom   \n",
       "2     /agent1/lightcontrol1        /lightControler     BedroomChildren   \n",
       "3     /agent4/lightcontrol4        /lightControler             Kitchen   \n",
       "4         /agent4/movement4        /movementSensor             Kitchen   \n",
       "\n",
       "     accessedNodeAddress accessedNodeType        operation  value  normality  \n",
       "0  /agent2/lightcontrol2  /lightControler  registerService    0.0          0  \n",
       "1  /agent3/lightcontrol3  /lightControler  registerService    0.0          0  \n",
       "2  /agent1/lightcontrol1  /lightControler  registerService    0.0          0  \n",
       "3  /agent4/lightcontrol4  /lightControler  registerService    0.0          0  \n",
       "4      /agent4/movement4  /movementSensor  registerService    0.0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = \"./mainSimulationAccessTraces.csv\"\n",
    "df = pd.read_csv(filePath)\n",
    "\n",
    "# For Missing Data\n",
    "df['accessedNodeType'] = df['accessedNodeType'].fillna(value='/Malicious')\n",
    "\n",
    "# For Unexpected Data\n",
    "df.loc[df.value=='twenty',\"value\"] = '20.0'\n",
    "df.loc[df.value=='false',\"value\"] = '0'\n",
    "df.loc[df.value=='true',\"value\"] = '1'\n",
    "df.loc[df.value=='none',\"value\"] = '0'\n",
    "df.loc[df.value=='0',\"value\"] = '0.0'\n",
    "df['value'] = df['value'].fillna(value='60.0')\n",
    "df = df.drop(df.index[df.value.str.contains(\"org.*\")])\n",
    "df.value = df.value.astype(float)\n",
    "\n",
    "# Dropping TimeStamp Column\n",
    "df = df.drop('timestamp', axis=1)\n",
    "\n",
    "# Converting Label class from Categorical to Numerical class\n",
    "def cat2num(x) :\n",
    "  if x == 'normal' :\n",
    "    return 0\n",
    "  else :\n",
    "    return 1\n",
    "\n",
    "df['normality'] = df['normality'].apply(cat2num)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "568UnujseLrn"
   },
   "source": [
    "# ***Data Exploration :-***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RPPzD9dUeit",
    "outputId": "379c7f2d-add1-4dff-ebb4-19e4d4f7232f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "| Source Location   |   Count |\n",
      "+===================+=========+\n",
      "| Garage            |   39499 |\n",
      "+-------------------+---------+\n",
      "| Watterroom        |   38368 |\n",
      "+-------------------+---------+\n",
      "| Entrance          |   38217 |\n",
      "+-------------------+---------+\n",
      "| Bathroom          |   28461 |\n",
      "+-------------------+---------+\n",
      "| Showerroom        |   28315 |\n",
      "+-------------------+---------+\n",
      "| Kitchen           |   18962 |\n",
      "+-------------------+---------+\n",
      "| Dinningroom       |   13429 |\n",
      "+-------------------+---------+\n",
      "| BedroomChildren   |   12836 |\n",
      "+-------------------+---------+\n",
      "| room_6            |   11642 |\n",
      "+-------------------+---------+\n",
      "| Bedroom           |   11009 |\n",
      "+-------------------+---------+\n",
      "| BedroomParents    |   10946 |\n",
      "+-------------------+---------+\n",
      "| room_8            |   10798 |\n",
      "+-------------------+---------+\n",
      "| room_9            |   10752 |\n",
      "+-------------------+---------+\n",
      "| Livingroom        |   10620 |\n",
      "+-------------------+---------+\n",
      "| room_2            |   10606 |\n",
      "+-------------------+---------+\n",
      "| room_1            |   10601 |\n",
      "+-------------------+---------+\n",
      "| room_3            |   10597 |\n",
      "+-------------------+---------+\n",
      "| room_5            |   10596 |\n",
      "+-------------------+---------+\n",
      "| room_4            |   10572 |\n",
      "+-------------------+---------+\n",
      "| room_7            |   10558 |\n",
      "+-------------------+---------+\n",
      "| room_10           |   10557 |\n",
      "+-------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "sourceLocationData = []\n",
    "\n",
    "for i, j in zip(df.sourceLocation.value_counts().index, df.sourceLocation.value_counts().values):\n",
    "  sourceLocationData.append([i, j])\n",
    "\n",
    "sourceLocationData = sorted(sourceLocationData, key=lambda x: x[1], reverse=True)\n",
    "print(tabulate(sourceLocationData, headers=[\"Source Location\", \"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce5uPZzzcv7W",
    "outputId": "3b144e45-522d-4c58-8739-4ecb12c7817a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------+\n",
      "| Destination Location   |   Count |\n",
      "+========================+=========+\n",
      "| Garage                 |   57100 |\n",
      "+------------------------+---------+\n",
      "| Entrance               |   54448 |\n",
      "+------------------------+---------+\n",
      "| Watterroom             |   38524 |\n",
      "+------------------------+---------+\n",
      "| Kitchen                |   19437 |\n",
      "+------------------------+---------+\n",
      "| BedroomChildren        |   12768 |\n",
      "+------------------------+---------+\n",
      "| Bathroom               |   12684 |\n",
      "+------------------------+---------+\n",
      "| Showerroom             |   12583 |\n",
      "+------------------------+---------+\n",
      "| BedroomParents         |   10938 |\n",
      "+------------------------+---------+\n",
      "| room_9                 |   10843 |\n",
      "+------------------------+---------+\n",
      "| room_2                 |   10828 |\n",
      "+------------------------+---------+\n",
      "| room_1                 |   10805 |\n",
      "+------------------------+---------+\n",
      "| Livingroom             |   10781 |\n",
      "+------------------------+---------+\n",
      "| Dinningroom            |   10759 |\n",
      "+------------------------+---------+\n",
      "| room_6                 |   10741 |\n",
      "+------------------------+---------+\n",
      "| room_3                 |   10732 |\n",
      "+------------------------+---------+\n",
      "| room_4                 |   10708 |\n",
      "+------------------------+---------+\n",
      "| room_5                 |   10687 |\n",
      "+------------------------+---------+\n",
      "| room_8                 |   10651 |\n",
      "+------------------------+---------+\n",
      "| room_7                 |   10649 |\n",
      "+------------------------+---------+\n",
      "| room_10                |   10648 |\n",
      "+------------------------+---------+\n",
      "| Bedroom                |   10627 |\n",
      "+------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "destinationLocationData = []\n",
    "\n",
    "for i, j in zip(df.destinationLocation.value_counts().index, df.destinationLocation.value_counts().values):\n",
    "  destinationLocationData.append([i, j])\n",
    "\n",
    "destinationLocationData = sorted(destinationLocationData, key=lambda x: x[1], reverse=True)\n",
    "print(tabulate(destinationLocationData, headers=[\"Destination Location\", \"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yq_pNw2eG1S",
    "outputId": "da1060c0-0a30-42c0-b57a-0dcea63bb1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+\n",
      "| Accessed Node Type   |   Count |\n",
      "+======================+=========+\n",
      "| /sensorService       |  130155 |\n",
      "+----------------------+---------+\n",
      "| /derived/boolean     |   94725 |\n",
      "+----------------------+---------+\n",
      "| /basic/number        |   90010 |\n",
      "+----------------------+---------+\n",
      "| /basic/text          |   42428 |\n",
      "+----------------------+---------+\n",
      "| /thermostat          |     313 |\n",
      "+----------------------+---------+\n",
      "| /Malicious           |     148 |\n",
      "+----------------------+---------+\n",
      "| /basic/composed      |     100 |\n",
      "+----------------------+---------+\n",
      "| /lightControler      |      23 |\n",
      "+----------------------+---------+\n",
      "| /movementSensor      |      22 |\n",
      "+----------------------+---------+\n",
      "| /batteryService      |       6 |\n",
      "+----------------------+---------+\n",
      "| /doorLockService     |       5 |\n",
      "+----------------------+---------+\n",
      "| /washingService      |       3 |\n",
      "+----------------------+---------+\n",
      "| /smartPhone          |       3 |\n",
      "+----------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "accessedNodeTypeData = []\n",
    "\n",
    "for i, j in zip(df.accessedNodeType.value_counts().index, df.accessedNodeType.value_counts().values):\n",
    "  accessedNodeTypeData.append([i, j])\n",
    "\n",
    "accessedNodeTypeData = sorted(accessedNodeTypeData, key=lambda x: x[1], reverse=True)\n",
    "print(tabulate(accessedNodeTypeData, headers=[\"Accessed Node Type\", \"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyPb46UNowgC",
    "outputId": "944e8736-529b-4199-855d-f0d2bc87c94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+\n",
      "| Accessed Node Type   |   Count |\n",
      "+======================+=========+\n",
      "| read                 |  248061 |\n",
      "+----------------------+---------+\n",
      "| write                |  109648 |\n",
      "+----------------------+---------+\n",
      "| lockSubtree          |     148 |\n",
      "+----------------------+---------+\n",
      "| registerService      |      84 |\n",
      "+----------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "operationData = []\n",
    "\n",
    "for i, j in zip(df.operation.value_counts().index, df.operation.value_counts().values):\n",
    "  operationData.append([i, j])\n",
    "\n",
    "operationData = sorted(operationData, key=lambda x: x[1], reverse=True)\n",
    "print(tabulate(operationData, headers=[\"Accessed Node Type\", \"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGYanVtUb5GT",
    "outputId": "c5052695-54d6-4c1b-f7fd-13d7296e3431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|   Normality |   Count |\n",
      "+=============+=========+\n",
      "|           0 |  347924 |\n",
      "+-------------+---------+\n",
      "|           1 |   10017 |\n",
      "+-------------+---------+\n"
     ]
    }
   ],
   "source": [
    "normalityData = []\n",
    "\n",
    "for i, j in zip(df.normality.value_counts().index, df.normality.value_counts().values):\n",
    "  normalityData.append([i, j])\n",
    "\n",
    "normalityData = sorted(normalityData, key=lambda x: x[1], reverse=True)\n",
    "print(tabulate(normalityData, headers=[\"Normality\", \"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5t-N66FmqDD"
   },
   "source": [
    "# ***Kolmogorov-Arnold-Network Implementation :-***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikV33U4luJge"
   },
   "source": [
    "* Kolmogorov-Arnold Representation Theorem :-\n",
    "  * $f(x) = f(x_{1},...,x_{n}) = âˆ‘_{q=1}^{2n + 1}ðš½_{q}(âˆ‘_{p=1}^{n}Î¦_{q, p}(x_{p}))$\n",
    "* Gausian Radial Basis Function (RBF) :-\n",
    "  * Computationally efficient and easy to calculate, with significant speed-ups in forward and backward passes.\n",
    "  * $b_{i}(u) = e^{(-(u - u_{i})^{2}/h)}$\n",
    "* Reflextional Switch Activation Function (RSWAF) :-\n",
    "  * Uses function which have reflextionary symmetry, allows us to retain performance while reducing computation time.\n",
    "  * $b_{i}(u) = 1 - (tanh((u - u_{i})/h))^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0nE8iEfAmpfX"
   },
   "outputs": [],
   "source": [
    "class KANLayer(nn.Module):\n",
    "  def __init__(self,\n",
    "               in_features,\n",
    "               out_features,\n",
    "               grid_size=5,\n",
    "               spline_order=3,\n",
    "               scale_noise=0.1,\n",
    "               scale_base=1.0,\n",
    "               scale_spline=1.0,\n",
    "               enable_standalone_scale_spline=True,\n",
    "               base_activation=torch.nn.SiLU,\n",
    "               grid_eps=0.2,\n",
    "               grid_range=[-1, 1],) :\n",
    "\n",
    "    super(KANLayer, self).__init__()\n",
    "    self.in_features = in_features\n",
    "    self.out_features = out_features\n",
    "    self.grid_size = grid_size\n",
    "    self.spline_order = spline_order\n",
    "\n",
    "    h = (grid_range[1] - grid_range[0])/grid_size\n",
    "\n",
    "    grid = ((torch.arange(-spline_order, grid_size + spline_order + 1) * h + grid_range[0]).expand(in_features, -1).contiguous())\n",
    "    self.register_buffer(\"grid\", grid)\n",
    "\n",
    "    self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "    self.spline_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features, grid_size + spline_order))\n",
    "\n",
    "    if enable_standalone_scale_spline:\n",
    "      self.spline_scaler = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "\n",
    "    self.scale_noise = scale_noise\n",
    "    self.scale_base = scale_base\n",
    "    self.scale_spline = scale_spline\n",
    "    self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
    "    self.base_activation = base_activation()\n",
    "    self.grid_eps = grid_eps\n",
    "\n",
    "    self.reset_parameters()\n",
    "\n",
    "  def reset_parameters(self) :\n",
    "    torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
    "\n",
    "    with torch.no_grad() :\n",
    "      noise = ((torch.rand(self.grid_size + 1, self.in_features, self.out_features)- 1 / 2)* self.scale_noise/ self.grid_size)\n",
    "      self.spline_weight.data.copy_((self.scale_spline if not self.enable_standalone_scale_spline else 1.0)* self.curve2coeff(self.grid.T[self.spline_order : -self.spline_order],noise,))\n",
    "\n",
    "      if self.enable_standalone_scale_spline :\n",
    "        torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
    "\n",
    "  def b_splines(self, x : torch.Tensor) :\n",
    "    assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "    grid : torch.Tensor = (self.grid)\n",
    "    x = x.unsqueeze(-1)\n",
    "    bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
    "\n",
    "    for k in range(1, self.spline_order + 1) :\n",
    "      bases = ((x - grid[:, : -(k + 1)])/ (grid[:, k:-1] - grid[:, : -(k + 1)])* bases[:, :, :-1]) + ((grid[:, k + 1 :] - x)/ (grid[:, k + 1 :] - grid[:, 1:(-k)])* bases[:, :, 1:])\n",
    "\n",
    "    assert bases.size() == (x.size(0), self.in_features, self.grid_size + self.spline_order,)\n",
    "    return bases.contiguous()\n",
    "\n",
    "  def curve2coeff(self, x : torch.Tensor, y : torch.Tensor) :\n",
    "    assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "    assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
    "\n",
    "    A = self.b_splines(x).transpose(0, 1)\n",
    "    B = y.transpose(0, 1)\n",
    "    solution = torch.linalg.lstsq(A, B).solution\n",
    "    result = solution.permute(2, 0, 1)\n",
    "\n",
    "    assert result.size() == (self.out_features, self.in_features, self.grid_size + self.spline_order,)\n",
    "    return result.contiguous()\n",
    "\n",
    "    @property\n",
    "    def scaled_spline_weight(self):\n",
    "      return self.spline_weight * (self.spline_scaler.unsqueeze(-1) if self.enable_standalone_scale_spline else 1.0)\n",
    "\n",
    "  def forward(self, x : torch.Tensor) :\n",
    "    assert x.size(-1) == self.in_features\n",
    "    original_shape = x.shape\n",
    "    x = x.view(-1, self.in_features)\n",
    "\n",
    "    base_output = F.linear(self.base_activation(x), self.base_weight)\n",
    "    spline_output = F.linear(self.b_splines(x).view(x.size(0), -1), self.scaled_spline_weight.view(self.out_features, -1),)\n",
    "    output = base_output + spline_output\n",
    "\n",
    "    output = output.view(*original_shape[:-1], self.out_features)\n",
    "    return output\n",
    "\n",
    "  def update_grid(self, x : torch.Tensor, margin=0.01) :\n",
    "    assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "    batch = x.size(0)\n",
    "\n",
    "    splines = self.b_splines(x)\n",
    "    splines = splines.permute(1, 0, 2)\n",
    "\n",
    "    orig_coeff = self.scaled_spline_weight\n",
    "    orig_coeff = orig_coeff.permute(1, 2, 0)\n",
    "\n",
    "    unreduced_spline_output = torch.bmm(splines, orig_coeff)\n",
    "    unreduced_spline_output = unreduced_spline_output.permute(1, 0, 2)\n",
    "\n",
    "    x_sorted = torch.sort(x, dim=0)[0]\n",
    "    grid_adaptive = x_sorted[torch.linspace(0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device)]\n",
    "\n",
    "    uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
    "    grid_uniform = (torch.arange(self.grid_size + 1, dtype=torch.float32, device=x.device).unsqueeze(1) * uniform_step + x_sorted[0] - margin)\n",
    "\n",
    "    grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "    grid = torch.concatenate([grid[:1] - uniform_step * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1), grid, grid[-1:] + uniform_step * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),], dim=0,)\n",
    "\n",
    "    self.grid.copy_(grid.T)\n",
    "    self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
    "\n",
    "  def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0) :\n",
    "    l1_fake = self.spline_weight.abs().mean(-1)\n",
    "    regularization_loss_activation = l1_fake.sum()\n",
    "    p = l1_fake / regularization_loss_activation\n",
    "    regularization_loss_entropy = -torch.sum(p * p.log())\n",
    "\n",
    "    return (regularize_activation * regularization_loss_activation + regularize_entropy * regularization_loss_entropy)\n",
    "\n",
    "class KAN(torch.nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      layers_hidden,\n",
    "      grid_size=5,\n",
    "      spline_order=3,\n",
    "      scale_noise=0.1,\n",
    "      scale_base=1.0,\n",
    "      scale_spline=1.0,\n",
    "      base_activation=torch.nn.SiLU,\n",
    "      grid_eps=0.02,\n",
    "      grid_range=[-1, 1],\n",
    "  ) :\n",
    "    super(KAN, self).__init__()\n",
    "    self.grid_size = grid_size\n",
    "    self.spline_order = spline_order\n",
    "\n",
    "    self.layers = torch.nn.ModuleList()\n",
    "    for in_features, out_features in zip(layers_hidden, layers_hidden[1:]) :\n",
    "      self.layers.append(KANLayer(\n",
    "          in_features,\n",
    "          out_features,\n",
    "          grid_size=grid_size,\n",
    "          spline_order=spline_order,\n",
    "          scale_noise=scale_noise,\n",
    "          scale_base=scale_base,\n",
    "          scale_spline=scale_spline,\n",
    "          base_activation=base_activation,\n",
    "          grid_eps=grid_eps,\n",
    "          grid_range=grid_range, ))\n",
    "\n",
    "  def forward(self, x: torch.Tensor, update_grid=False) :\n",
    "    for layer in self.layers :\n",
    "      if update_grid :\n",
    "        layer.update_grid(x)\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "  def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
    "    return sum(layer.regularization_loss(regularize_activation, regularize_entropy) for layer in self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2238,
     "status": "ok",
     "timestamp": 1718862390961,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "ZdeVvGntsHJR"
   },
   "outputs": [],
   "source": [
    "X0 = df.iloc[:, 0].values.reshape(-1, 1)\n",
    "X1 = df.iloc[:, 1].values.reshape(-1, 1)\n",
    "X2 = df.iloc[:, 2].values.reshape(-1, 1)\n",
    "X3 = df.iloc[:, 3].values.reshape(-1, 1)\n",
    "X4 = df.iloc[:, 4].values.reshape(-1, 1)\n",
    "X5 = df.iloc[:, 5].values.reshape(-1, 1)\n",
    "X6 = df.iloc[:, 6].values.reshape(-1, 1)\n",
    "X7 = df.iloc[:, 7].values.reshape(-1, 1)\n",
    "X8 = df.iloc[:, 8].values.reshape(-1, 1)\n",
    "X9 = df.iloc[:, 9].values.reshape(-1, 1)\n",
    "X10 = df.iloc[:, 10].values.reshape(-1, 1)\n",
    "\n",
    "y = df['normality'].values\n",
    "\n",
    "X0 = TargetEncoder(target_type=\"binary\").fit_transform(X0, y)\n",
    "X1 = TargetEncoder(target_type=\"binary\").fit_transform(X1, y)\n",
    "X2 = TargetEncoder(target_type=\"binary\").fit_transform(X2, y)\n",
    "X3 = TargetEncoder(target_type=\"binary\").fit_transform(X3, y)\n",
    "X4 = TargetEncoder(target_type=\"binary\").fit_transform(X4, y)\n",
    "X5 = TargetEncoder(target_type=\"binary\").fit_transform(X5, y)\n",
    "X6 = TargetEncoder(target_type=\"binary\").fit_transform(X6, y)\n",
    "X7 = TargetEncoder(target_type=\"binary\").fit_transform(X7, y)\n",
    "X8 = TargetEncoder(target_type=\"binary\").fit_transform(X8, y)\n",
    "X9 = TargetEncoder(target_type=\"binary\").fit_transform(X9, y)\n",
    "\n",
    "X10 = StandardScaler().fit_transform(X10.reshape(-1, 1))\n",
    "\n",
    "X = np.concatenate((X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718862390961,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "g6GKzBz-exbJ",
    "outputId": "dac11690-8f5e-4baf-df61-e4b31c06a96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape :  torch.Size([286352, 11])\n",
      "Testing Data Shape :  torch.Size([71589, 11])\n",
      "Training Label Shape :  torch.Size([286352])\n",
      "Testing Label Shape :  torch.Size([71589])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape : \", X_train.shape)\n",
    "print(\"Testing Data Shape : \", X_test.shape)\n",
    "print(\"Training Label Shape : \", y_train.shape)\n",
    "print(\"Testing Label Shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718862390961,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "YXMzF0kjfEr0"
   },
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "valLoader = DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1718862390961,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "ArmsaNeNMsZU"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718862390962,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "82x8ZgVKWHX7"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcMEwZxvfPVV"
   },
   "source": [
    "***Efficient -KAN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "277YnuMqmfps"
   },
   "outputs": [],
   "source": [
    "model = KAN([X_train.shape[1], 100, len(set(y_train))])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7T5VaT3hv5y2",
    "outputId": "4157c92a-bead-470b-c22b-dc36ef5960e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter layers.0.base_weight requires grad!\n",
      "Parameter layers.0.spline_weight requires grad!\n",
      "Parameter layers.0.spline_scaler requires grad!\n",
      "Parameter layers.1.base_weight requires grad!\n",
      "Parameter layers.1.spline_weight requires grad!\n",
      "Parameter layers.1.spline_scaler requires grad!\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f\"Parameter {name} does not require grad!\")\n",
    "    else: print(f\"Parameter {name} requires grad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "JaHp0gDTrV9x",
    "outputId": "53b2906b-bbf8-445a-ddfd-9cec1852aedd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 745.85batch/s, accuracy=0, loss=2.38, lr=0.001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 781.27batch/s, accuracy=0, loss=2.38, lr=0.0008]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 778.71batch/s, accuracy=0, loss=2.41, lr=0.00064]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 780.15batch/s, accuracy=0, loss=2.4, lr=0.000512]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 777.78batch/s, accuracy=0.125, loss=2.39, lr=0.00041] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 775.13batch/s, accuracy=0, loss=2.4, lr=0.000328]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 774.31batch/s, accuracy=0.125, loss=2.37, lr=0.000262] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 783.51batch/s, accuracy=0, loss=2.38, lr=0.00021]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 783.57batch/s, accuracy=0, loss=2.39, lr=0.000168]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 783.84batch/s, accuracy=0.0625, loss=2.34, lr=0.000134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 783.26batch/s, accuracy=0, loss=2.36, lr=0.000107]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 778.12batch/s, accuracy=0, loss=2.38, lr=8.59e-5]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 767.56batch/s, accuracy=0, loss=2.41, lr=6.87e-5]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 772.70batch/s, accuracy=0, loss=2.39, lr=5.5e-5]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Loss: 2.4296 - Accuracy: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:05<00:00, 774.93batch/s, accuracy=0, loss=2.4, lr=4.4e-5]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Loss: 2.4296 - Accuracy: 0.0262\n",
      "Validation - Loss: 2.4296 - Accuracy: 0.0248\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  epoch_accuracy = 0\n",
    "  with tqdm(trainLoader, unit=\"batch\") as pbar:\n",
    "        for i, (feats, labels) in enumerate(pbar):\n",
    "            feats = feats.to(device).requires_grad_(True)\n",
    "            labels = labels.to(device)\n",
    "            #if not feats.requires_grad : print(\"Inputs do not require gradients!\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feats)\n",
    "            #if output.grad_fn is None : print(\"Output does not have a grad_fn!\")\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            #if loss.grad_fn is None : print(\"Loss does not have a grad_fn!\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "  scheduler.step()\n",
    "  print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/len(trainLoader):.4f} - Accuracy: {epoch_accuracy/len(trainLoader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "val_loss = 0\n",
    "val_accuracy = 0\n",
    "with torch.no_grad():\n",
    "    for feats, labels in valLoader:\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        output = model(feats)\n",
    "        loss = criterion(output, labels)\n",
    "        accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "        val_loss += loss.item()\n",
    "        val_accuracy += accuracy.item()\n",
    "\n",
    "print(f\"Validation - Loss: {val_loss/len(valLoader):.4f} - Accuracy: {val_accuracy/len(valLoader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcBTmYTCQZT9",
    "outputId": "26a1c33f-83a9-4b02-b38c-8f4fdde8e781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters : 286363000\n",
      "Trainable Parameters : 286363000\n"
     ]
    }
   ],
   "source": [
    "parameter_efficient_kan = count_parameters(model)\n",
    "print(f\"Total Parameters : {parameter_efficient_kan[0]}\")\n",
    "print(f\"Trainable Parameters : {parameter_efficient_kan[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkl2TiH2OqV2"
   },
   "source": [
    "***Faster-KAN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 2060,
     "status": "ok",
     "timestamp": 1718862512105,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "gFQOQNem4F3P"
   },
   "outputs": [],
   "source": [
    "train_flag = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "model_ = fkan.FasterKAN([X_train.shape[1], 2*X_train.shape[1] - 1, len(set(y_train))], grid_min=-1.2, grid_max=0.2, num_grids=5, exponent=2, inv_denominator=0.5, train_grid=train_flag, train_inv_denominator=train_flag).to(device)\n",
    "model_.to(device)\n",
    "\n",
    "optimizer_ = torch.optim.AdamW(model_.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler_ = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_, mode='min', factor=0.6, patience=1, verbose=True)\n",
    "criterion_ = torch.nn.CrossEntropyLoss()\n",
    "earlyStopping = EarlyStopping(patience=7, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 884229,
     "status": "ok",
     "timestamp": 1718863562318,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "7mzB4jqPP0X1",
    "outputId": "471970ea-037e-487e-b63f-a1066fa6290c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:21<00:00, 204.10it/s, accuracy=1, loss=0.00523, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val Loss: 0.0003840293617355967, Val Accuracy: 0.9902638673539231\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:21<00:00, 205.25it/s, accuracy=1, loss=9.17e-5, lr=0.001]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val Loss: 0.00027631370219443707, Val Accuracy: 0.9920937574208328\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4475/4475 [00:21<00:00, 205.94it/s, accuracy=1, loss=0.000207, lr=0.001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val Loss: 0.0002468040536086141, Val Accuracy: 0.9927642514911509\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 61/4475 [00:00<00:21, 201.81it/s, accuracy=1, loss=0.0358, lr=0.001]    "
     ]
    }
   ],
   "source": [
    "epochs_ = 100\n",
    "val_loss = 0.0\n",
    "\n",
    "for epoch in range(epochs_):\n",
    "  model_.train()\n",
    "  with tqdm(trainLoader) as pbar:\n",
    "    for i, (feats, labels) in enumerate(pbar):\n",
    "      feats = feats.to(device).requires_grad_(True)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      optimizer_.zero_grad()\n",
    "\n",
    "      output = model_(feats)\n",
    "\n",
    "      loss = criterion_(output, labels)\n",
    "      loss.backward()\n",
    "\n",
    "      torch.nn.utils.clip_grad_norm_(model_.parameters(), max_norm=1.0)\n",
    "\n",
    "      optimizer_.step()\n",
    "\n",
    "      accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "      pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer_.param_groups[0]['lr'])\n",
    "\n",
    "  model_.eval()\n",
    "  with torch.no_grad():\n",
    "    val_correct = 0\n",
    "    for feats, labels in valLoader:\n",
    "        feats = feats.to(device)\n",
    "        output = model_(feats)\n",
    "        val_loss += criterion_(output, labels.to(device)).item()\n",
    "        preds = output.argmax(dim=1)\n",
    "        val_correct += (preds == labels.to(device)).sum().item()\n",
    "\n",
    "\n",
    "  val_loss /= len(valLoader.dataset)\n",
    "  val_accuracy = val_correct / len(valLoader.dataset)\n",
    "\n",
    "  scheduler_.step(val_loss)\n",
    "\n",
    "  print(f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "  print(f\"Current Learning Rate: {optimizer_.param_groups[0]['lr']}\")\n",
    "\n",
    "  earlyStopping(val_loss)\n",
    "  if earlyStopping.early_stop:\n",
    "    print(\"Triggering Early Stop!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1718863665840,
     "user": {
      "displayName": "Shubh Mishra",
      "userId": "02195341365578258841"
     },
     "user_tz": -330
    },
    "id": "03m1ymkpKl5u",
    "outputId": "bed615d0-f11e-4e3d-e305-fc67c8aefd82"
   },
   "outputs": [],
   "source": [
    "parameter_faster_kan = count_parameters(model_)\n",
    "print(f\"Total Parameters : {parameter_faster_kan[0]}\")\n",
    "print(f\"Trainable Parameters : {parameter_faster_kan[1]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
